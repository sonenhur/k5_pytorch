{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonenhur/k5_pytorch/blob/main/CatAndDog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wohp39jYXcIB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상수 정의\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 4"
      ],
      "metadata": {
        "id": "qUePhyrHfE1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVhE0ZjCXcIC"
      },
      "outputs": [],
      "source": [
        "# 이미지 변환 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([256, 256]),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드\n",
        "train_dataset = ImageFolder(root='/data/catanddog/train', transform=transform)\n",
        "test_dataset = ImageFolder(root='/data/catanddog/test', transform=transform)"
      ],
      "metadata": {
        "id": "OEvhJPgRsCYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더 생성\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "4A-d-Xn1sFL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 딕셔너리 생성\n",
        "dataloaders = {'train': train_loader, 'val': test_loader}"
      ],
      "metadata": {
        "id": "1ks0rpz-sHZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxdx679RXcID"
      },
      "source": [
        "------------------------------------------------------------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWWYWLrlXcID"
      },
      "source": [
        "## 모델 만들기\n",
        "PyTorch에서 신경망 모델은 [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) 을\n",
        "상속받는 클래스(class)를 생성하여 정의합니다. ``__init__`` 함수에서 신경망의 계층(layer)들을 정의하고 ``forward`` 함수에서\n",
        "신경망에 데이터를 어떻게 전달할지 지정합니다. 가능한 경우 GPU 또는 MPS로 신경망을 이동시켜 연산을 가속(accelerate)합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 사용할 CPU나 GPU 장치\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5k5xou-MdVg",
        "outputId": "b7ac15fc-6254-402a-d3e4-5ae9f5ec0a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpfhTQTxXcIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7017ba97-7d6c-48e0-fa68-6ba98bd8ea94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(16, 120, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (9): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=300000, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Dropout(p=0.5, inplace=False)\n",
            "    (5): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# LeNet 모델 정의\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5, padding='same'),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(6, 16, 5, padding='same'),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 120, 7),\n",
        "            nn.BatchNorm2d(120),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(120*50*50, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(64, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = self.classifier(features)\n",
        "        return out\n",
        "\n",
        "model = LeNet().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LeNet 모델의 예시 사용\n",
        "input = torch.randn(BATCH_SIZE, 3, 224, 224).to(device)\n",
        "output = model(input)\n",
        "print(type(output), len(output), output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsBxR75-a0TS",
        "outputId": "8f40d841-5171-44c8-e507-3f902b660be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> 128 torch.Size([128, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet 신경망 사용"
      ],
      "metadata": {
        "id": "g3zvbdph0krn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "# 미리 학습된 ResNet 모델 로드\n",
        "model_ft = models.resnet50(weights='IMAGENET1K_V1')\n",
        "\n",
        "# 매개변수 동결\n",
        "def set_parameter(model, grad=False): #함수 생성하기 / 함수를 변수처럼 쓰기\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "set_parameter(model_ft, False)\n",
        "\n",
        "# 분류기 조정\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(2048, 256),  # ResNet-18 출력 크기와 일치하도록 입력 크기 조정\n",
        "    nn.Dropout(),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 64),\n",
        "    nn.Dropout(),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "# ResNet의 완전연결 레이어를 사용자 커스텀 분류기로 교체\n",
        "model_ft.fc = classifier\n",
        "model = model_ft.to(device)"
      ],
      "metadata": {
        "id": "zYqU79g_zJqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "def summary_model(model):\n",
        "  print(summary(model=model, input_size=(32, 3, 224, 224), col_width=20,\n",
        "        col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0))\n",
        "\n",
        "\n",
        "summary_model(model)"
      ],
      "metadata": {
        "id": "l1j-3HD0mN_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669b65da-5107-48d1-c993-727867e33c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
            "========================================================================================================================\n",
            "ResNet (ResNet)                          [32, 3, 224, 224]    [32, 2]              --                   Partial\n",
            "├─Conv2d (conv1)                         [32, 3, 224, 224]    [32, 64, 112, 112]   (9,408)              False\n",
            "├─BatchNorm2d (bn1)                      [32, 64, 112, 112]   [32, 64, 112, 112]   (128)                False\n",
            "├─ReLU (relu)                            [32, 64, 112, 112]   [32, 64, 112, 112]   --                   --\n",
            "├─MaxPool2d (maxpool)                    [32, 64, 112, 112]   [32, 64, 56, 56]     --                   --\n",
            "├─Sequential (layer1)                    [32, 64, 56, 56]     [32, 256, 56, 56]    --                   False\n",
            "│    └─Bottleneck (0)                    [32, 64, 56, 56]     [32, 256, 56, 56]    --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 64, 56, 56]     (4,096)              False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
            "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
            "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 64, 56, 56]     [32, 256, 56, 56]    (16,384)             False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]    [32, 256, 56, 56]    (512)                False\n",
            "│    │    └─Sequential (downsample)      [32, 64, 56, 56]     [32, 256, 56, 56]    (16,896)             False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
            "│    └─Bottleneck (1)                    [32, 256, 56, 56]    [32, 256, 56, 56]    --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 256, 56, 56]    [32, 64, 56, 56]     (16,384)             False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
            "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
            "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 64, 56, 56]     [32, 256, 56, 56]    (16,384)             False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]    [32, 256, 56, 56]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
            "│    └─Bottleneck (2)                    [32, 256, 56, 56]    [32, 256, 56, 56]    --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 256, 56, 56]    [32, 64, 56, 56]     (16,384)             False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
            "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
            "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 64, 56, 56]     [32, 256, 56, 56]    (16,384)             False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]    [32, 256, 56, 56]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
            "├─Sequential (layer2)                    [32, 256, 56, 56]    [32, 512, 28, 28]    --                   False\n",
            "│    └─Bottleneck (0)                    [32, 256, 56, 56]    [32, 512, 28, 28]    --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 256, 56, 56]    [32, 128, 56, 56]    (32,768)             False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 128, 56, 56]    [32, 128, 56, 56]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 56, 56]    [32, 128, 56, 56]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 128, 56, 56]    [32, 128, 28, 28]    (147,456)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
            "│    │    └─Sequential (downsample)      [32, 256, 56, 56]    [32, 512, 28, 28]    (132,096)            False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
            "│    └─Bottleneck (1)                    [32, 512, 28, 28]    [32, 512, 28, 28]    --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 128, 28, 28]    (65,536)             False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
            "│    └─Bottleneck (2)                    [32, 512, 28, 28]    [32, 512, 28, 28]    --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 128, 28, 28]    (65,536)             False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
            "│    └─Bottleneck (3)                    [32, 512, 28, 28]    [32, 512, 28, 28]    --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 128, 28, 28]    (65,536)             False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
            "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
            "├─Sequential (layer3)                    [32, 512, 28, 28]    [32, 1024, 14, 14]   --                   False\n",
            "│    └─Bottleneck (0)                    [32, 512, 28, 28]    [32, 1024, 14, 14]   --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 256, 28, 28]    (131,072)            False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 256, 28, 28]    [32, 256, 28, 28]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 28, 28]    [32, 256, 28, 28]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 256, 28, 28]    [32, 256, 14, 14]    (589,824)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
            "│    │    └─Sequential (downsample)      [32, 512, 28, 28]    [32, 1024, 14, 14]   (526,336)            False\n",
            "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
            "│    └─Bottleneck (1)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
            "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
            "│    └─Bottleneck (2)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
            "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
            "│    └─Bottleneck (3)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
            "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
            "│    └─Bottleneck (4)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
            "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
            "│    └─Bottleneck (5)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
            "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
            "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
            "├─Sequential (layer4)                    [32, 1024, 14, 14]   [32, 2048, 7, 7]     --                   False\n",
            "│    └─Bottleneck (0)                    [32, 1024, 14, 14]   [32, 2048, 7, 7]     --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 512, 14, 14]    (524,288)            False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 512, 14, 14]    [32, 512, 14, 14]    (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 14, 14]    [32, 512, 14, 14]    --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 512, 14, 14]    [32, 512, 7, 7]      (2,359,296)          False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 512, 7, 7]      [32, 2048, 7, 7]     (1,048,576)          False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]     [32, 2048, 7, 7]     (4,096)              False\n",
            "│    │    └─Sequential (downsample)      [32, 1024, 14, 14]   [32, 2048, 7, 7]     (2,101,248)          False\n",
            "│    │    └─ReLU (relu)                  [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   --\n",
            "│    └─Bottleneck (1)                    [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 2048, 7, 7]     [32, 512, 7, 7]      (1,048,576)          False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      (2,359,296)          False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 512, 7, 7]      [32, 2048, 7, 7]     (1,048,576)          False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]     [32, 2048, 7, 7]     (4,096)              False\n",
            "│    │    └─ReLU (relu)                  [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   --\n",
            "│    └─Bottleneck (2)                    [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   False\n",
            "│    │    └─Conv2d (conv1)               [32, 2048, 7, 7]     [32, 512, 7, 7]      (1,048,576)          False\n",
            "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
            "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      (2,359,296)          False\n",
            "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
            "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
            "│    │    └─Conv2d (conv3)               [32, 512, 7, 7]      [32, 2048, 7, 7]     (1,048,576)          False\n",
            "│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]     [32, 2048, 7, 7]     (4,096)              False\n",
            "│    │    └─ReLU (relu)                  [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   --\n",
            "├─AdaptiveAvgPool2d (avgpool)            [32, 2048, 7, 7]     [32, 2048, 1, 1]     --                   --\n",
            "├─Sequential (fc)                        [32, 2048]           [32, 2]              --                   True\n",
            "│    └─Linear (0)                        [32, 2048]           [32, 256]            524,544              True\n",
            "│    └─Dropout (1)                       [32, 256]            [32, 256]            --                   --\n",
            "│    └─ReLU (2)                          [32, 256]            [32, 256]            --                   --\n",
            "│    └─Linear (3)                        [32, 256]            [32, 64]             16,448               True\n",
            "│    └─Dropout (4)                       [32, 64]             [32, 64]             --                   --\n",
            "│    └─ReLU (5)                          [32, 64]             [32, 64]             --                   --\n",
            "│    └─Linear (6)                        [32, 64]             [32, 2]              130                  True\n",
            "│    └─Softmax (7)                       [32, 2]              [32, 2]              --                   --\n",
            "========================================================================================================================\n",
            "Total params: 24,049,154\n",
            "Trainable params: 541,122\n",
            "Non-trainable params: 23,508,032\n",
            "Total mult-adds (Units.GIGABYTES): 130.81\n",
            "========================================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 5690.44\n",
            "Params size (MB): 96.20\n",
            "Estimated Total Size (MB): 5805.91\n",
            "========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6geLqWsdXcIE"
      },
      "source": [
        "------------------------------------------------------------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB8mBIrCXcIE"
      },
      "source": [
        "## 모델 매개변수 최적화하기\n",
        "모델을 학습하려면 [손실 함수(loss function)](https://pytorch.org/docs/stable/nn.html#loss-functions) 와\n",
        "[옵티마이저(optimizer)](https://pytorch.org/docs/stable/optim.html) 가 필요합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jggxHjfEXcIE"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y25Kqw_UXcIF"
      },
      "source": [
        "각 학습 단계(training loop)에서 모델은 (배치(batch)로 제공되는) 학습 데이터셋에 대한 예측을 수행하고,\n",
        "예측 오류를 역전파하여 모델의 매개변수를 조정합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3A-GO8QXcIF"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 예측 오류 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            current = batch * len(X)\n",
        "            print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANv59VSMXcIF"
      },
      "source": [
        "모델이 학습하고 있는지를 확인하기 위해 테스트 데이터셋으로 모델의 성능을 확인합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6dlLLkMXcIF"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcbXRqUpXcIF"
      },
      "source": [
        "학습 단계는 여러번의 반복 단계 (*에폭(epochs)*) 를 거쳐서 수행됩니다. 각 에폭에서는 모델은 더 나은 예측을 하기 위해  매개변수를 학습합니다.\n",
        "각 에폭마다 모델의 정확도(accuracy)와 손실(loss)을 출력합니다; 에폭마다 정확도가 증가하고 손실이 감소하는 것을 보려고 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1uFIcuWXcIF",
        "outputId": "bfdefa4a-cc16-42b2-c743-4957c928e02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.696088  [    0/  385]\n",
            "Training Loss: 0.6718061119318008\n",
            "Test Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.683744 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.684438  [    0/  385]\n",
            "Training Loss: 0.6991800218820572\n",
            "Test Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.675025 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.679315  [    0/  385]\n",
            "Training Loss: 0.6627065390348434\n",
            "Test Error: \n",
            " Accuracy: 63.3%, Avg loss: 0.662511 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.669964  [    0/  385]\n",
            "Training Loss: 0.6507727056741714\n",
            "Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 0.653045 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# 학습\n",
        "epochs = 4\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train(train_loader, model, loss_fn, optimizer)\n",
        "    print(f\"Training Loss: {train_loss}\")\n",
        "    test(test_loader, model, loss_fn)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCfnOTZcXcIG"
      },
      "source": [
        "[모델을 학습하는 방법](optimization_tutorial.html) 을 자세히 알아보세요.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "argmax  \n",
        "0.7 / 0.3 에서 0 나온다 -> cat  \n",
        "0.3 / 0.7 에서 1 나온다 -> dog  "
      ],
      "metadata": {
        "id": "7eB5b1OclxTm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOs4bEZqXcIG"
      },
      "source": [
        "------------------------------------------------------------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDuT0oarXcIG"
      },
      "source": [
        "## 모델 저장하기\n",
        "모델을 저장하는 일반적인 방법은 (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)을\n",
        "직렬화(serialize)하는 것입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3GbcR40XcIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc61c4c-1007-4cea-9b9e-22f5927f0666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKOoI74uXcIG"
      },
      "source": [
        "## 모델 불러오기\n",
        "\n",
        "모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQD06emTXcIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "93686f4f-3f55-4716-e0d1-d7b320d7a271"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for LeNet:\n\tMissing key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.4.weight\", \"features.4.bias\", \"features.5.weight\", \"features.5.bias\", \"features.5.running_mean\", \"features.5.running_var\", \"features.8.weight\", \"features.8.bias\", \"features.9.weight\", \"features.9.bias\", \"features.9.running_mean\", \"features.9.running_var\", \"classifier.2.weight\", \"classifier.2.bias\", \"classifier.5.weight\", \"classifier.5.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.num_batches_tracked\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.num_batches_tracked\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer1.2.bn3.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.bn3.num_batches_tracked\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.1.bn3.num_batches_tracked\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.2.bn3.num_batches_tracked\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.num_batches_tracked\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.num_batches_tracked\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer2.3.bn3.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.num_batches_tracked\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.num_batches_tracked\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.num_batches_tracked\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.num_batches_tracked\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.num_batches_tracked\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.num_batches_tracked\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.num_batches_tracked\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.num_batches_tracked\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.num_batches_tracked\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.num_batches_tracked\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.num_batches_tracked\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.num_batches_tracked\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.num_batches_tracked\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.num_batches_tracked\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.num_batches_tracked\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.num_batches_tracked\", \"fc.0.weight\", \"fc.0.bias\", \"fc.3.weight\", \"fc.3.bias\", \"fc.6.weight\", \"fc.6.bias\". ",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LeNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\torch_book\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LeNet:\n\tMissing key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.4.weight\", \"features.4.bias\", \"features.5.weight\", \"features.5.bias\", \"features.5.running_mean\", \"features.5.running_var\", \"features.8.weight\", \"features.8.bias\", \"features.9.weight\", \"features.9.bias\", \"features.9.running_mean\", \"features.9.running_var\", \"classifier.2.weight\", \"classifier.2.bias\", \"classifier.5.weight\", \"classifier.5.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.num_batches_tracked\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.num_batches_tracked\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1..."
          ]
        }
      ],
      "source": [
        "model = LeNet().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbAssN3zXcIG"
      },
      "source": [
        "이제 이 모델을 사용해서 예측을 할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVZUhHxFXcIH"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rSzcz70XcIH"
      },
      "source": [
        "[모델을 저장하고 불러오는 방법](saveloadrun_tutorial.html) 을 자세히 알아보세요.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}